"""
ç ”ç©¶å‘˜æ™ºèƒ½ä½“ - è´Ÿè´£ä¿¡æ¯æ”¶é›†å’Œç ”ç©¶
"""
import os
import sys
import logging
from pathlib import Path
from dotenv import load_dotenv
from typing import Dict, Any, List

# æ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½•å¹¶åŠ è½½ç¯å¢ƒå˜é‡
current_dir = Path(__file__).parent
project_root = current_dir.parent.parent  # å‘ä¸Šä¸¤çº§åˆ°é¡¹ç›®æ ¹ç›®å½•
env_path = project_root / '.env'

print(f"ğŸ” æŸ¥æ‰¾ .env æ–‡ä»¶: {env_path}")
if env_path.exists():
    load_dotenv(env_path)
    print("âœ… .env æ–‡ä»¶åŠ è½½æˆåŠŸ")
else:
    print("âš ï¸  .env æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œå°è¯•å½“å‰ç›®å½•")
    load_dotenv()

# ç°åœ¨æ‰å¯¼å…¥éœ€è¦API keyçš„æ¨¡å—
from crewai import Agent
from crewai_tools import SerperDevTool, WebsiteSearchTool

class ResearcherAgent:
    """ç ”ç©¶å‘˜æ™ºèƒ½ä½“ - ä¸“é—¨è´Ÿè´£ä¿¡æ¯æ”¶é›†å’ŒéªŒè¯"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self._initialize_tools()

    def _initialize_tools(self):
        """åˆå§‹åŒ–ç ”ç©¶å·¥å…·"""
        # é¦–å…ˆæ£€æŸ¥ OpenAI API Key
        openai_key = os.getenv("OPENAI_API_KEY")
        print(f"ğŸ”‘ OpenAI API Key çŠ¶æ€: {'å·²è®¾ç½®' if openai_key else 'æœªè®¾ç½®'}")

        if not openai_key:
            raise ValueError("âŒ æœªæ‰¾åˆ° OPENAI_API_KEYï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶é…ç½®")

        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰SERPER API KEY
            serper_key = os.getenv("SERPER_API_KEY")
            if serper_key:
                self.search_tool = SerperDevTool()
                self.logger.info("âœ… SerperDevTool åˆå§‹åŒ–æˆåŠŸ")
            else:
                self.search_tool = None
                self.logger.warning("âš ï¸  æœªæ‰¾åˆ°SERPER_API_KEYï¼Œå°†ä½¿ç”¨åŸºç¡€æœç´¢åŠŸèƒ½")

            # ç½‘ç«™æœç´¢å·¥å…· - éœ€è¦ OpenAI API Key
            print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ– WebsiteSearchTool...")
            self.website_tool = WebsiteSearchTool()
            self.logger.info("âœ… WebsiteSearchTool åˆå§‹åŒ–æˆåŠŸ")

        except Exception as e:
            self.logger.error(f"âŒ å·¥å…·åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            print(f"ğŸ’¡ è°ƒè¯•ä¿¡æ¯: {str(e)}")
            raise

    def create_agent(self, config: Dict[str, Any]) -> Agent:
        """
        åˆ›å»ºç ”ç©¶å‘˜æ™ºèƒ½ä½“

        Args:
            config: æ™ºèƒ½ä½“é…ç½®å­—å…¸

        Returns:
            Agent: é…ç½®å¥½çš„ç ”ç©¶å‘˜æ™ºèƒ½ä½“
        """
        try:
            # å‡†å¤‡å·¥å…·åˆ—è¡¨
            tools = []
            if self.search_tool:
                tools.append(self.search_tool)
            tools.append(self.website_tool)

            # åˆ›å»ºAgent
            agent = Agent(
                role=config['role'],
                goal=config['goal'],
                backstory=config['backstory'],
                tools=tools,
                max_iter=config.get('max_iter', 3),
                max_execution_time=config.get('max_execution_time', 300),
                verbose=config.get('verbose', True),
                allow_delegation=config.get('allow_delegation', False),
                memory=True
            )

            self.logger.info("âœ… ç ”ç©¶å‘˜æ™ºèƒ½ä½“åˆ›å»ºæˆåŠŸ")
            return agent

        except Exception as e:
            self.logger.error(f"âŒ åˆ›å»ºç ”ç©¶å‘˜æ™ºèƒ½ä½“å¤±è´¥: {str(e)}")
            raise

    def validate_sources(self, sources: List[str]) -> List[Dict[str, Any]]:
        """
        éªŒè¯ä¿¡æ¯æºçš„å¯é æ€§

        Args:
            sources: ä¿¡æ¯æºURLåˆ—è¡¨

        Returns:
            List[Dict]: éªŒè¯åçš„æºä¿¡æ¯
        """
        validated_sources = []

        # å¯ä¿¡åŸŸååˆ—è¡¨
        trusted_domains = [
            'gov.cn', 'edu.cn', 'org.cn', 'gov', 'edu', 'org',
            'ieee.org', 'nature.com', 'science.org',
            'cnki.net', 'wanfangdata.com.cn',
            'baidu.com', 'tencent.com', 'alibaba.com'
        ]

        for source in sources:
            try:
                # åŸºç¡€URLéªŒè¯
                if not source.startswith(('http://', 'https://')):
                    continue

                # æ£€æŸ¥æ˜¯å¦ä¸ºå¯ä¿¡åŸŸå
                is_trusted = any(domain in source.lower() for domain in trusted_domains)

                source_info = {
                    'url': source,
                    'is_trusted': is_trusted,
                    'domain': self._extract_domain(source),
                    'validation_score': self._calculate_trust_score(source)
                }

                validated_sources.append(source_info)

            except Exception as e:
                self.logger.warning(f"âš ï¸  æºéªŒè¯å¤±è´¥: {source}, é”™è¯¯: {str(e)}")
                continue

        return validated_sources

    def _extract_domain(self, url: str) -> str:
        """æå–åŸŸå"""
        try:
            from urllib.parse import urlparse
            return urlparse(url).netloc
        except:
            return "unknown"

    def _calculate_trust_score(self, url: str) -> float:
        """
        è®¡ç®—ä¿¡ä»»åº¦è¯„åˆ† (0-1)
        """
        score = 0.5  # åŸºç¡€åˆ†æ•°

        # æ”¿åºœå’Œæ•™è‚²æœºæ„åŠ åˆ†
        if any(domain in url.lower() for domain in ['.gov', '.edu', '.org']):
            score += 0.3

        # çŸ¥ååª’ä½“å’Œå¹³å°åŠ åˆ†
        if any(domain in url.lower() for domain in ['baidu', 'tencent', 'alibaba', 'xinhua', 'people']):
            score += 0.2

        # HTTPSåŠ åˆ†
        if url.startswith('https://'):
            score += 0.1

        return min(score, 1.0)

    def extract_key_information(self, research_text: str) -> Dict[str, Any]:
        """
        ä»ç ”ç©¶æ–‡æœ¬ä¸­æå–å…³é”®ä¿¡æ¯

        Args:
            research_text: ç ”ç©¶æ–‡æœ¬

        Returns:
            Dict: æå–çš„å…³é”®ä¿¡æ¯
        """
        # è¿™é‡Œå¯ä»¥é›†æˆNLPå·¥å…·è¿›è¡Œæ›´æ™ºèƒ½çš„ä¿¡æ¯æå–
        # æš‚æ—¶è¿”å›åŸºç¡€ç»“æ„
        return {
            'word_count': len(research_text.split()),
            'key_topics': [],  # å¯ä»¥æ·»åŠ å…³é”®è¯æå–
            'data_points': [],  # å¯ä»¥æ·»åŠ æ•°æ®ç‚¹è¯†åˆ«
            'sources_count': research_text.count('http'),
            'last_updated': None
        }


# ç”¨äºå•ç‹¬æµ‹è¯•çš„å‡½æ•°
def test_researcher_agent():
    """æµ‹è¯•ç ”ç©¶å‘˜æ™ºèƒ½ä½“"""
    print("ğŸ” æµ‹è¯•ç ”ç©¶å‘˜æ™ºèƒ½ä½“...")
    print(f"ğŸ“ å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    print(f"ğŸ”‘ OPENAI_API_KEY: {'å·²è®¾ç½®' if os.getenv('OPENAI_API_KEY') else 'æœªè®¾ç½®'}")

    try:
        # æ¨¡æ‹Ÿé…ç½®
        config = {
            'role': 'å†…å®¹ç ”ç©¶ä¸“å®¶',
            'goal': 'æ”¶é›†å…³äºAIå‘å±•çš„æœ€æ–°ä¿¡æ¯',
            'backstory': 'ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„ç ”ç©¶ä¸“å®¶',
            'max_iter': 2,
            'verbose': True
        }

        # åˆ›å»ºç ”ç©¶å‘˜
        print("ğŸš€ æ­£åœ¨åˆ›å»ºç ”ç©¶å‘˜æ™ºèƒ½ä½“...")
        researcher = ResearcherAgent()
        agent = researcher.create_agent(config)

        print("âœ… ç ”ç©¶å‘˜æ™ºèƒ½ä½“åˆ›å»ºæˆåŠŸ")
        print(f"ğŸ“‹ Agentè§’è‰²: {agent.role}")
        print(f"ğŸ¯ Agentç›®æ ‡: {agent.goal}")
        print(f"ğŸ› ï¸  å·¥å…·æ•°é‡: {len(agent.tools) if agent.tools else 0}")

        # æµ‹è¯•æºéªŒè¯
        test_sources = [
            'https://www.gov.cn/test',
            'https://baidu.com/news',
            'http://unknown-site.com'
        ]

        validated = researcher.validate_sources(test_sources)
        print(f"\nğŸ“Š æºéªŒè¯ç»“æœ: {len(validated)} ä¸ªæº")
        for source in validated:
            print(f"  - {source['domain']}: ä¿¡ä»»åº¦ {source['validation_score']:.2f}")

        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        return True

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        print("\nğŸ”§ æ•…éšœæ’é™¤å»ºè®®:")
        print("1. æ£€æŸ¥ .env æ–‡ä»¶æ˜¯å¦åœ¨é¡¹ç›®æ ¹ç›®å½•")
        print("2. ç¡®è®¤ OPENAI_API_KEY æ ¼å¼æ­£ç¡®")
        print("3. éªŒè¯ API Key æ˜¯å¦æœ‰æ•ˆ")
        print("4. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        return False


if __name__ == "__main__":
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO)

    # è¿è¡Œæµ‹è¯•
    test_researcher_agent()