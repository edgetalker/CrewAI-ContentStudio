"""
ç¼–è¾‘å‘˜æ™ºèƒ½ä½“ - è´Ÿè´£å†…å®¹è´¨é‡æ§åˆ¶å’Œä¼˜åŒ–
"""
import os
import sys
import logging
from pathlib import Path
from dotenv import load_dotenv
from typing import Dict, Any, List, Tuple
import re
import json
from datetime import datetime

# æ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½•å¹¶åŠ è½½ç¯å¢ƒå˜é‡
current_dir = Path(__file__).parent
project_root = current_dir.parent.parent
env_path = project_root / '.env'

if env_path.exists():
    load_dotenv(env_path)

from crewai import Agent


class EditorAgent:
    """ç¼–è¾‘å‘˜æ™ºèƒ½ä½“ - ä¸“é—¨è´Ÿè´£å†…å®¹è´¨é‡æ§åˆ¶å’Œä¼˜åŒ–"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self._check_environment()
        self._initialize_tools()
        self._load_editing_rules()

    def _check_environment(self):
        """æ£€æŸ¥ç¯å¢ƒå˜é‡é…ç½®"""
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("âŒ æœªæ‰¾åˆ° OPENAI_API_KEYï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶é…ç½®")
        print("ğŸ”‘ OpenAI API Key: å·²è®¾ç½®")

    def _initialize_tools(self):
        """åˆå§‹åŒ–ç¼–è¾‘å·¥å…·"""
        try:
            # ç¼–è¾‘è€…ä½¿ç”¨LLMçš„å†…ç½®è¯­è¨€å¤„ç†å’Œåˆ†æèƒ½åŠ›
            # ä¸“æ³¨äºè´¨é‡æ§åˆ¶ã€è¯­è¨€ä¼˜åŒ–å’Œæ ¼å¼è§„èŒƒ
            print("âœ… ç¼–è¾‘å·¥å…·åˆå§‹åŒ–æˆåŠŸï¼ˆä½¿ç”¨å†…ç½®è¯­è¨€å¤„ç†èƒ½åŠ›ï¼‰")

        except Exception as e:
            self.logger.error(f"âŒ å·¥å…·åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            print(f"ğŸ’¡ è°ƒè¯•ä¿¡æ¯: {str(e)}")
            raise

    def _load_editing_rules(self):
        """åŠ è½½ç¼–è¾‘è§„åˆ™å’Œè´¨é‡æ ‡å‡†"""
        self.editing_rules = {
            'grammar_rules': {
                'punctuation_check': True,
                'sentence_structure': True,
                'word_choice': True,
                'tense_consistency': True
            },
            'style_rules': {
                'tone_consistency': True,
                'voice_active_preferred': True,
                'paragraph_length_optimal': True,
                'transition_smooth': True
            },
            'seo_rules': {
                'keyword_density': {'min': 1, 'max': 3},  # 1-3%
                'title_optimization': True,
                'meta_description': True,
                'heading_structure': True
            },
            'readability_rules': {
                'sentence_length_avg': 20,  # å¹³å‡20å­—ä»¥ä¸‹
                'paragraph_length_max': 150,  # æœ€å¤š150å­—
                'complex_words_ratio': 0.15,  # å¤æ‚è¯æ±‡ä¸è¶…è¿‡15%
                'passive_voice_ratio': 0.1  # è¢«åŠ¨è¯­æ€ä¸è¶…è¿‡10%
            },
            'format_rules': {
                'heading_hierarchy': True,
                'list_formatting': True,
                'emphasis_appropriate': True,
                'link_formatting': True
            }
        }

        # å¸¸è§é”™è¯¯æ¨¡å¼
        self.common_errors = {
            'grammar': [
                r'çš„çš„',  # é‡å¤çš„"çš„"
                r'äº†äº†',  # é‡å¤çš„"äº†"
                r'åœ¨åœ¨',  # é‡å¤ä»‹è¯
                r'æ˜¯æ˜¯',  # é‡å¤ç³»åŠ¨è¯
            ],
            'punctuation': [
                r'ï¼Œï¼Œ',  # é‡å¤é€—å·
                r'ã€‚ã€‚',  # é‡å¤å¥å·
                r'ï¼Ÿï¼Ÿ',  # é‡å¤é—®å·
                r'ï¼ï¼',  # é‡å¤æ„Ÿå¹å·
            ],
            'spacing': [
                r'\s+',  # å¤šä½™ç©ºæ ¼
                r'\n\n\n+',  # å¤šä½™æ¢è¡Œ
            ]
        }

        print(f"ğŸ“‹ åŠ è½½äº† {len(self.editing_rules)} ç±»ç¼–è¾‘è§„åˆ™")

    def create_agent(self, config: Dict[str, Any]) -> Agent:
        """
        åˆ›å»ºç¼–è¾‘å‘˜æ™ºèƒ½ä½“

        Args:
            config: æ™ºèƒ½ä½“é…ç½®å­—å…¸

        Returns:
            Agent: é…ç½®å¥½çš„ç¼–è¾‘å‘˜æ™ºèƒ½ä½“
        """
        try:
            # ç¼–è¾‘å‘˜æ™ºèƒ½ä½“ä¸“æ³¨äºè´¨é‡æ§åˆ¶ï¼Œä½¿ç”¨LLMçš„å†…ç½®è¯­è¨€å¤„ç†èƒ½åŠ›

            # åˆ›å»ºAgent
            agent = Agent(
                role=config['role'],
                goal=config['goal'],
                backstory=config['backstory'],
                tools=[],  # ä½¿ç”¨å†…ç½®ç¼–è¾‘èƒ½åŠ›
                max_iter=config.get('max_iter', 2),
                max_execution_time=config.get('max_execution_time', 250),
                verbose=config.get('verbose', True),
                allow_delegation=config.get('allow_delegation', False),
                memory=True
            )

            self.logger.info("âœ… ç¼–è¾‘å‘˜æ™ºèƒ½ä½“åˆ›å»ºæˆåŠŸ")
            print(f"ğŸ“ ç¼–è¾‘å‘˜æ™ºèƒ½ä½“å·²åˆ›å»º - {agent.role}")
            return agent

        except Exception as e:
            self.logger.error(f"âŒ åˆ›å»ºç¼–è¾‘å‘˜æ™ºèƒ½ä½“å¤±è´¥: {str(e)}")
            raise

    def analyze_content_quality(self, content: str, content_type: str = "blog_post") -> Dict[str, Any]:
        """
        åˆ†æå†…å®¹è´¨é‡

        Args:
            content: å¾…åˆ†æçš„å†…å®¹
            content_type: å†…å®¹ç±»å‹

        Returns:
            Dict: è´¨é‡åˆ†æç»“æœ
        """
        try:
            quality_analysis = {
                'overall_score': 0,
                'grammar_analysis': self._check_grammar(content),
                'readability_analysis': self._check_readability(content),
                'seo_analysis': self._check_seo_optimization(content),
                'structure_analysis': self._check_structure(content, content_type),
                'style_analysis': self._check_style_consistency(content),
                'improvement_suggestions': []
            }

            # è®¡ç®—æ€»ä½“è¯„åˆ†
            quality_analysis['overall_score'] = self._calculate_overall_score(quality_analysis)

            # ç”Ÿæˆæ”¹è¿›å»ºè®®
            quality_analysis['improvement_suggestions'] = self._generate_improvement_suggestions(quality_analysis)

            return quality_analysis

        except Exception as e:
            self.logger.error(f"âŒ å†…å®¹è´¨é‡åˆ†æå¤±è´¥: {str(e)}")
            raise

    def _check_grammar(self, content: str) -> Dict[str, Any]:
        """æ£€æŸ¥è¯­æ³•è´¨é‡"""
        grammar_issues = []

        # æ£€æŸ¥å¸¸è§è¯­æ³•é”™è¯¯
        for error_type, patterns in self.common_errors.items():
            for pattern in patterns:
                matches = re.findall(pattern, content)
                if matches:
                    grammar_issues.append({
                        'type': error_type,
                        'pattern': pattern,
                        'count': len(matches),
                        'examples': matches[:3]  # æœ€å¤šæ˜¾ç¤º3ä¸ªä¾‹å­
                    })

        # åŸºç¡€è¯­æ³•æ£€æŸ¥
        sentence_count = len(re.findall(r'[ã€‚ï¼ï¼Ÿ]', content))
        word_count = len(content.replace(' ', '').replace('\n', ''))
        avg_sentence_length = word_count / sentence_count if sentence_count > 0 else 0

        grammar_score = max(0, 100 - len(grammar_issues) * 10)

        return {
            'score': grammar_score,
            'issues_found': len(grammar_issues),
            'issues_detail': grammar_issues,
            'avg_sentence_length': round(avg_sentence_length, 1),
            'total_sentences': sentence_count,
            'total_words': word_count
        }

    def _check_readability(self, content: str) -> Dict[str, Any]:
        """æ£€æŸ¥å¯è¯»æ€§"""
        # æ®µè½åˆ†æ
        paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]
        paragraph_lengths = [len(p) for p in paragraphs]
        avg_paragraph_length = sum(paragraph_lengths) / len(paragraph_lengths) if paragraph_lengths else 0

        # å¥å­åˆ†æ
        sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', content)
        sentences = [s.strip() for s in sentences if s.strip()]
        sentence_lengths = [len(s) for s in sentences]
        avg_sentence_length = sum(sentence_lengths) / len(sentence_lengths) if sentence_lengths else 0

        # å¯è¯»æ€§è¯„åˆ† (ç®€åŒ–ç‰ˆ)
        readability_score = 100

        # æ®µè½é•¿åº¦æ‰£åˆ†
        if avg_paragraph_length > 200:
            readability_score -= 20
        elif avg_paragraph_length > 150:
            readability_score -= 10

        # å¥å­é•¿åº¦æ‰£åˆ†
        if avg_sentence_length > 30:
            readability_score -= 20
        elif avg_sentence_length > 25:
            readability_score -= 10

        return {
            'score': max(0, readability_score),
            'avg_paragraph_length': round(avg_paragraph_length, 1),
            'avg_sentence_length': round(avg_sentence_length, 1),
            'total_paragraphs': len(paragraphs),
            'total_sentences': len(sentences),
            'readability_level': self._get_readability_level(readability_score)
        }

    def _check_seo_optimization(self, content: str) -> Dict[str, Any]:
        """æ£€æŸ¥SEOä¼˜åŒ–"""
        # æ ‡é¢˜æ£€æŸ¥
        titles = re.findall(r'^#+\s+(.+)$', content, re.MULTILINE)
        h1_titles = re.findall(r'^#\s+(.+)$', content, re.MULTILINE)

        # å…³é”®è¯å¯†åº¦åˆ†æ (ç¤ºä¾‹)
        # åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿™é‡Œéœ€è¦ä¼ å…¥å®é™…çš„ç›®æ ‡å…³é”®è¯
        sample_keywords = ['äººå·¥æ™ºèƒ½', 'AI', 'æŠ€æœ¯', 'å‘å±•']
        keyword_analysis = {}

        total_words = len(content.replace(' ', '').replace('\n', ''))

        for keyword in sample_keywords:
            count = content.count(keyword)
            density = (count * len(keyword) / total_words * 100) if total_words > 0 else 0
            keyword_analysis[keyword] = {
                'count': count,
                'density': round(density, 2)
            }

        seo_score = 80  # åŸºç¡€åˆ†

        # æ ‡é¢˜ç»“æ„æ£€æŸ¥
        if not h1_titles:
            seo_score -= 20
        elif len(h1_titles) > 1:
            seo_score -= 10

        if len(titles) < 3:
            seo_score -= 10

        return {
            'score': max(0, seo_score),
            'title_analysis': {
                'h1_count': len(h1_titles),
                'total_headings': len(titles),
                'heading_hierarchy': len(titles) >= 3
            },
            'keyword_analysis': keyword_analysis,
            'meta_elements': {
                'title_optimized': len(h1_titles) == 1,
                'headings_present': len(titles) > 0
            }
        }

    def _check_structure(self, content: str, content_type: str) -> Dict[str, Any]:
        """æ£€æŸ¥å†…å®¹ç»“æ„"""
        # åŸºæœ¬ç»“æ„å…ƒç´ æ£€æŸ¥
        has_introduction = bool(re.search(r'(å¼•è¨€|ä»‹ç»|æ¦‚è¿°|èƒŒæ™¯)', content[:200]))
        has_conclusion = bool(re.search(r'(ç»“è®º|æ€»ç»“|å±•æœ›|å»ºè®®)', content[-200:]))
        has_headings = bool(re.findall(r'^#+\s+', content, re.MULTILINE))

        paragraphs = [p.strip() for p in content.split('\n\n') if p.strip()]

        structure_score = 70  # åŸºç¡€åˆ†

        if has_introduction:
            structure_score += 10
        if has_conclusion:
            structure_score += 10
        if has_headings:
            structure_score += 10
        if len(paragraphs) >= 5:
            structure_score += 10

        return {
            'score': min(100, structure_score),
            'has_introduction': has_introduction,
            'has_conclusion': has_conclusion,
            'has_headings': has_headings,
            'paragraph_count': len(paragraphs),
            'logical_flow': len(paragraphs) >= 3
        }

    def _check_style_consistency(self, content: str) -> Dict[str, Any]:
        """æ£€æŸ¥é£æ ¼ä¸€è‡´æ€§"""
        # è¯­è°ƒä¸€è‡´æ€§æ£€æŸ¥ (ç®€åŒ–)
        formal_indicators = len(re.findall(r'(å› æ­¤|ç„¶è€Œ|æ­¤å¤–|ç»¼ä¸Šæ‰€è¿°|æ ¹æ®)', content))
        casual_indicators = len(re.findall(r'(å…¶å®|ä¸è¿‡|å½“ç„¶|è¯´å®è¯)', content))

        # æ—¶æ€ä¸€è‡´æ€§æ£€æŸ¥
        past_tense = len(re.findall(r'(äº†|è¿‡|æ›¾|å·²)', content))
        present_tense = len(re.findall(r'(æ­£åœ¨|ç›®å‰|ç°åœ¨|å½“å‰)', content))

        style_score = 85  # åŸºç¡€åˆ†

        # è¯­è°ƒä¸ä¸€è‡´æ‰£åˆ†
        if formal_indicators > 0 and casual_indicators > 0:
            if abs(formal_indicators - casual_indicators) > 2:
                style_score -= 15

        return {
            'score': max(0, style_score),
            'tone_analysis': {
                'formal_indicators': formal_indicators,
                'casual_indicators': casual_indicators,
                'tone_consistency': abs(formal_indicators - casual_indicators) <= 2
            },
            'tense_analysis': {
                'past_tense_usage': past_tense,
                'present_tense_usage': present_tense
            }
        }

    def _get_readability_level(self, score: int) -> str:
        """è·å–å¯è¯»æ€§çº§åˆ«"""
        if score >= 90:
            return 'excellent'
        elif score >= 80:
            return 'good'
        elif score >= 70:
            return 'fair'
        elif score >= 60:
            return 'difficult'
        else:
            return 'very_difficult'

    def _calculate_overall_score(self, analysis: Dict[str, Any]) -> int:
        """è®¡ç®—æ€»ä½“è´¨é‡è¯„åˆ†"""
        scores = []

        # æ”¶é›†å„é¡¹è¯„åˆ†
        if 'grammar_analysis' in analysis:
            scores.append(analysis['grammar_analysis']['score'])
        if 'readability_analysis' in analysis:
            scores.append(analysis['readability_analysis']['score'])
        if 'seo_analysis' in analysis:
            scores.append(analysis['seo_analysis']['score'])
        if 'structure_analysis' in analysis:
            scores.append(analysis['structure_analysis']['score'])
        if 'style_analysis' in analysis:
            scores.append(analysis['style_analysis']['score'])

        # è®¡ç®—åŠ æƒå¹³å‡åˆ†
        if scores:
            overall_score = sum(scores) / len(scores)
            return round(overall_score)

        return 0

    def _generate_improvement_suggestions(self, analysis: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        suggestions = []

        # è¯­æ³•å»ºè®®
        grammar_score = analysis.get('grammar_analysis', {}).get('score', 100)
        if grammar_score < 80:
            suggestions.append("è¯­æ³•æ£€æŸ¥ï¼šå‘ç°å¤šå¤„è¯­æ³•é”™è¯¯ï¼Œå»ºè®®ä»”ç»†æ ¡å¯¹")

        # å¯è¯»æ€§å»ºè®®
        readability = analysis.get('readability_analysis', {})
        if readability.get('avg_sentence_length', 0) > 25:
            suggestions.append("å¥å­é•¿åº¦ï¼šå»ºè®®å°†é•¿å¥æ‹†åˆ†ä¸ºæ›´çŸ­çš„å¥å­ï¼Œæé«˜å¯è¯»æ€§")

        if readability.get('avg_paragraph_length', 0) > 150:
            suggestions.append("æ®µè½é•¿åº¦ï¼šå»ºè®®ç¼©çŸ­æ®µè½é•¿åº¦ï¼Œå¢åŠ æ¢è¡Œå’Œåˆ†æ®µ")

        # SEOå»ºè®®
        seo_analysis = analysis.get('seo_analysis', {})
        if seo_analysis.get('title_analysis', {}).get('h1_count', 0) != 1:
            suggestions.append("SEOä¼˜åŒ–ï¼šç¡®ä¿æœ‰ä¸”ä»…æœ‰ä¸€ä¸ªä¸»æ ‡é¢˜(H1)")

        # ç»“æ„å»ºè®®
        structure = analysis.get('structure_analysis', {})
        if not structure.get('has_introduction'):
            suggestions.append("å†…å®¹ç»“æ„ï¼šå»ºè®®æ·»åŠ å¼•è¨€éƒ¨åˆ†")

        if not structure.get('has_conclusion'):
            suggestions.append("å†…å®¹ç»“æ„ï¼šå»ºè®®æ·»åŠ ç»“è®ºæˆ–æ€»ç»“éƒ¨åˆ†")

        return suggestions[:5]  # æœ€å¤šè¿”å›5ä¸ªå»ºè®®

    def generate_editing_report(self, analysis: Dict[str, Any]) -> Dict[str, Any]:
        """
        ç”Ÿæˆç¼–è¾‘æŠ¥å‘Š

        Args:
            analysis: è´¨é‡åˆ†æç»“æœ

        Returns:
            Dict: ç¼–è¾‘æŠ¥å‘Š
        """
        overall_score = analysis.get('overall_score', 0)

        # ç¡®å®šè´¨é‡ç­‰çº§
        if overall_score >= 90:
            quality_grade = 'A+'
            status = 'excellent'
        elif overall_score >= 80:
            quality_grade = 'A'
            status = 'good'
        elif overall_score >= 70:
            quality_grade = 'B'
            status = 'acceptable'
        elif overall_score >= 60:
            quality_grade = 'C'
            status = 'needs_improvement'
        else:
            quality_grade = 'D'
            status = 'major_revision_needed'

        report = {
            'overall_assessment': {
                'score': overall_score,
                'grade': quality_grade,
                'status': status,
                'recommendation': self._get_recommendation(status)
            },
            'detailed_scores': {
                'grammar': analysis.get('grammar_analysis', {}).get('score', 0),
                'readability': analysis.get('readability_analysis', {}).get('score', 0),
                'seo': analysis.get('seo_analysis', {}).get('score', 0),
                'structure': analysis.get('structure_analysis', {}).get('score', 0),
                'style': analysis.get('style_analysis', {}).get('score', 0)
            },
            'priority_improvements': analysis.get('improvement_suggestions', []),
            'editing_checklist': self._generate_editing_checklist(analysis),
            'publication_readiness': overall_score >= 80,
            'estimated_revision_time': self._estimate_revision_time(analysis)
        }

        return report

    def _get_recommendation(self, status: str) -> str:
        """è·å–æ¨èè¡ŒåŠ¨"""
        recommendations = {
            'excellent': 'å†…å®¹è´¨é‡ä¼˜ç§€ï¼Œå¯ä»¥ç›´æ¥å‘å¸ƒ',
            'good': 'å†…å®¹è´¨é‡è‰¯å¥½ï¼Œå»ºè®®å¾®è°ƒåå‘å¸ƒ',
            'acceptable': 'å†…å®¹åŸºæœ¬åˆæ ¼ï¼Œå»ºè®®é€‚åº¦ä¿®æ”¹åå‘å¸ƒ',
            'needs_improvement': 'å†…å®¹éœ€è¦æ”¹è¿›ï¼Œå»ºè®®ä¿®æ”¹åé‡æ–°å®¡æ ¸',
            'major_revision_needed': 'å†…å®¹éœ€è¦å¤§å¹…ä¿®æ”¹ï¼Œå»ºè®®é‡å†™å…³é”®éƒ¨åˆ†'
        }
        return recommendations.get(status, 'éœ€è¦è¿›ä¸€æ­¥è¯„ä¼°')

    def _generate_editing_checklist(self, analysis: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆç¼–è¾‘æ£€æŸ¥æ¸…å•"""
        checklist = []

        # åŸºç¡€æ£€æŸ¥é¡¹
        checklist.extend([
            'æ£€æŸ¥è¯­æ³•å’Œæ‹¼å†™é”™è¯¯',
            'ç¡®è®¤æ ‡ç‚¹ç¬¦å·ä½¿ç”¨æ­£ç¡®',
            'éªŒè¯æ®µè½é•¿åº¦é€‚ä¸­',
            'æ£€æŸ¥é€»è¾‘æµç•…æ€§'
        ])

        # æ ¹æ®åˆ†æç»“æœæ·»åŠ ç‰¹å®šæ£€æŸ¥é¡¹
        if analysis.get('seo_analysis', {}).get('score', 100) < 80:
            checklist.append('ä¼˜åŒ–SEOå…ƒç´ ï¼ˆæ ‡é¢˜ã€å…³é”®è¯ï¼‰')

        if analysis.get('structure_analysis', {}).get('score', 100) < 80:
            checklist.append('å®Œå–„å†…å®¹ç»“æ„ï¼ˆå¼•è¨€ã€ç»“è®ºï¼‰')

        return checklist

    def _estimate_revision_time(self, analysis: Dict[str, Any]) -> str:
        """ä¼°ç®—ä¿®æ”¹æ—¶é—´"""
        overall_score = analysis.get('overall_score', 100)

        if overall_score >= 90:
            return '5-10åˆ†é’Ÿ'
        elif overall_score >= 80:
            return '15-20åˆ†é’Ÿ'
        elif overall_score >= 70:
            return '30-45åˆ†é’Ÿ'
        elif overall_score >= 60:
            return '1-2å°æ—¶'
        else:
            return '2å°æ—¶ä»¥ä¸Š'


# æµ‹è¯•å‡½æ•°
def test_editor_agent():
    """æµ‹è¯•ç¼–è¾‘å‘˜æ™ºèƒ½ä½“"""
    print("ğŸ“ æµ‹è¯•ç¼–è¾‘å‘˜æ™ºèƒ½ä½“...")
    print(f"ğŸ“ å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    print(f"ğŸ”‘ OPENAI_API_KEY: {'å·²è®¾ç½®' if os.getenv('OPENAI_API_KEY') else 'æœªè®¾ç½®'}")

    try:
        # æ¨¡æ‹Ÿé…ç½®
        config = {
            'role': 'è´¨é‡ä¿è¯ä¸“å®¶',
            'goal': 'ç¡®ä¿å†…å®¹è´¨é‡è¾¾åˆ°ä¸“ä¸šå‘å¸ƒæ ‡å‡†',
            'backstory': 'ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„ç¼–è¾‘ä¸“å®¶',
            'max_iter': 2,
            'verbose': True
        }

        # åˆ›å»ºç¼–è¾‘å‘˜
        print("ğŸš€ æ­£åœ¨åˆ›å»ºç¼–è¾‘å‘˜æ™ºèƒ½ä½“...")
        editor = EditorAgent()
        agent = editor.create_agent(config)

        print("âœ… ç¼–è¾‘å‘˜æ™ºèƒ½ä½“åˆ›å»ºæˆåŠŸ")
        print(f"ğŸ“‹ Agentè§’è‰²: {agent.role}")
        print(f"ğŸ¯ Agentç›®æ ‡: {agent.goal}")
        print(f"ğŸ› ï¸  å·¥å…·æ•°é‡: {len(agent.tools) if agent.tools else 0} (ä½¿ç”¨å†…ç½®ç¼–è¾‘èƒ½åŠ›)")

        # æ¨¡æ‹Ÿéœ€è¦ç¼–è¾‘çš„å†…å®¹
        sample_content = """
# äººå·¥æ™ºèƒ½çš„å‘å±•è¶‹åŠ¿

äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨è¿‘å¹´æ¥å–å¾—äº†é£é€Ÿå‘å±•ã€‚æ®ç»Ÿè®¡ï¼Œ2024å¹´å…¨çƒAIå¸‚åœºè§„æ¨¡è¾¾åˆ°1840äº¿ç¾å…ƒã€‚

## æŠ€æœ¯çªç ´

æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ æŠ€æœ¯ä¸æ–­è¿›æ­¥ï¼Œåœ¨å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸè¡¨ç°çªå‡ºã€‚ä¸“å®¶è®¤ä¸ºAIå°†åœ¨æœªæ¥5å¹´å†…å½»åº•æ”¹å˜åˆ¶é€ ä¸šçš„æ ¼å±€ã€‚

## åº”ç”¨åœºæ™¯

ç›®å‰AIæŠ€æœ¯å·²ç»å¹¿æ³›åº”ç”¨äºåŒ»ç–—ã€é‡‘èã€æ•™è‚²ç­‰å¤šä¸ªè¡Œä¸šã€‚ä¼ä¸šå¯¹AIæŠ•èµ„çš„å…´è¶£æ—¥ç›Šå¢é•¿ï¼Œ85%çš„ä¼ä¸šæ­£åœ¨è€ƒè™‘AIç›¸å…³æŠ•èµ„ã€‚

æ€»çš„æ¥è¯´ï¼Œäººå·¥æ™ºèƒ½çš„å‘å±•å‰æ™¯éå¸¸å¹¿é˜”ï¼Œå€¼å¾—æŒç»­å…³æ³¨ã€‚
        """

        # æµ‹è¯•å†…å®¹è´¨é‡åˆ†æ
        print("\nğŸ” æµ‹è¯•å†…å®¹è´¨é‡åˆ†æ...")
        quality_analysis = editor.analyze_content_quality(sample_content, "blog_post")

        print(f"  - æ€»ä½“è¯„åˆ†: {quality_analysis['overall_score']}/100")
        print(f"  - è¯­æ³•è¯„åˆ†: {quality_analysis['grammar_analysis']['score']}/100")
        print(f"  - å¯è¯»æ€§è¯„åˆ†: {quality_analysis['readability_analysis']['score']}/100")
        print(f"  - SEOè¯„åˆ†: {quality_analysis['seo_analysis']['score']}/100")
        print(f"  - ç»“æ„è¯„åˆ†: {quality_analysis['structure_analysis']['score']}/100")
        print(f"  - é£æ ¼è¯„åˆ†: {quality_analysis['style_analysis']['score']}/100")

        # æµ‹è¯•ç¼–è¾‘æŠ¥å‘Šç”Ÿæˆ
        print("\nğŸ“Š æµ‹è¯•ç¼–è¾‘æŠ¥å‘Šç”Ÿæˆ...")
        editing_report = editor.generate_editing_report(quality_analysis)

        print(f"  - è´¨é‡ç­‰çº§: {editing_report['overall_assessment']['grade']}")
        print(f"  - å‘å¸ƒçŠ¶æ€: {editing_report['overall_assessment']['status']}")
        print(f"  - å‘å¸ƒå°±ç»ª: {'æ˜¯' if editing_report['publication_readiness'] else 'å¦'}")
        print(f"  - é¢„è®¡ä¿®æ”¹æ—¶é—´: {editing_report['estimated_revision_time']}")
        print(f"  - æ”¹è¿›å»ºè®®: {len(editing_report['priority_improvements'])} æ¡")

        # æ˜¾ç¤ºæ”¹è¿›å»ºè®®
        if editing_report['priority_improvements']:
            print("\nğŸ’¡ ä¸»è¦æ”¹è¿›å»ºè®®:")
            for i, suggestion in enumerate(editing_report['priority_improvements'], 1):
                print(f"    {i}. {suggestion}")

        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        return True

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        print("\nğŸ”§ æ•…éšœæ’é™¤å»ºè®®:")
        print("1. æ£€æŸ¥ .env æ–‡ä»¶é…ç½®")
        print("2. ç¡®è®¤ OPENAI_API_KEY æœ‰æ•ˆ")
        print("3. æ£€æŸ¥ç½‘ç»œè¿æ¥")
        return False


if __name__ == "__main__":
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(level=logging.INFO)

    # è¿è¡Œæµ‹è¯•
    test_editor_agent()